makeCacheMatrix <- function(x = matrix()) {
xinv <- NULL # this is where the result of inversion is stored
# A setter function, use this to set a matrix to object created by makeCacheMatrix function
# e.g makeCacheMatrix(testmatrix) # here we work on testmatrix
# makeCacheMatrix$set(testmatrix1) # here we work on testmatrix1
set <- function(y) {
x <<- y
xinv <<- NULL # it also initialises xinv to null
}
get <- function() x # return the input matrix
setInv <- function(inv) xinv <<- inv # set the inversed matrix
getInv <- function() xinv # return the inversed matrix
# return a list that contains these functions, so that we can use
# makeCacheMatrix object like these
# x <- makeCacheMatrix(testmatrix)
# x$set(newmatrix) # to change matrix
# x$get # to get the setted matrix
# x$setInv # to set the inversed matrix
# x$getInv # to get the inversed matrix
list(set = set, get = get,
setInv = setInv,
getInv = getInv)
}
mine<- makeCacheMatrix(matrix(1:4,2,2))
mine$get()
makeCacheMatrix <- function(x = matrix()) {
xinv <- NULL # this is where the result of inversion is stored
# A setter function, use this to set a matrix to object created by makeCacheMatrix function
# e.g makeCacheMatrix(testmatrix) # here we work on testmatrix
# makeCacheMatrix$set(testmatrix1) # here we work on testmatrix1
set <- function(y) {
x <<- y
xinv <<- NULL # it also initialises xinv to null
}
get <- function() x # return the input matrix
setInv <- function(inv) xinv <<- inv # set the inversed matrix
getInv <- function() xinv # return the inversed matrix
# return a list that contains these functions, so that we can use
# makeCacheMatrix object like these
# x <- makeCacheMatrix(testmatrix)
# x$set(newmatrix) # to change matrix
# x$get # to get the setted matrix
# x$setInv # to set the inversed matrix
# x$getInv # to get the inversed matrix
#list(set = set, get = get,
#    setInv = setInv,
#   getInv = getInv)
}
mine<- makeCacheMatrix(matrix(1:4,2,2))
mine$get()
makeCacheMatrix <- function(x = matrix()) {
inv <- NULL #Initializing where the inverse will be stored
setX<- function(y) { #Sets the matrix that will be worked with
x <<- y
inv <<- NULL
}
getX <- function() x #Simply grabbing the matrix
setInverse <- function(inverse) inv <<- inverse #Fuction to inverse the matrix
getInverse <- function() inv #Getting in the inverse
#Listing the functions so that they can used after makeCacheMatrix initializes X
list(setX = setX, get = getX,
setInverse = setInverse,
getInverse = getInverse)
}
#The following function calculates the inverse of the matrix that
# was created with the above function. However, it first checks to see if the
#inverse has already been calculated. If so, it `get`s the inverse from the
#cache and skips the computation. Otherwise, it calculates the mean of
#the data and sets the value of the mean in the cache via the `setmean`
#function.
cacheSolve <- function(x, ...) {
inv <- x$getInverse()
if(!is.null(inv)) {
message("Grabbing your stored/cached data for you!")
return(inv)
}
data <- x$get()
inv <- solve(data, ...)
x$setmean(inv)
inv
}
makeCacheMatrix(matrix(1:4,2,2))
x<-makeCacheMatrix(matrix(1:4,2,2))
x
## The following code can be used to:
## A) Create and store the inverse of a matrix
## B) Call a matrix, determine if its inverse has been computed and/or stored, then either compute the inverse or call the stored one
## The following fuction helps to create the matrix and can be used to store its inverse
makeCacheMatrix <- function(x = matrix()) {
inv <- NULL #Initializing where the inverse will be stored
setX<- function(y) { #Sets the matrix that will be worked with
x <<- y
inv <<- NULL
}
getX <- function() x #Simply grabbing the matrix
setInverse <- function(inverse) inv <<- inverse #Fuction to inverse the matrix
getInverse <- function() inv #Getting in the inverse
#Listing the functions so that they can used after makeCacheMatrix initializes X
list(setX = setX, getX = getX,
setInverse = setInverse,
getInverse = getInverse)
}
#The following function calculates the inverse of the matrix that
# was created with the above function. However, it first checks to see if the
#inverse has already been calculated. If so, it `get`s the inverse from the
#cache and skips the computation. Otherwise, it calculates the mean of
#the data and sets the value of the mean in the cache via the `setmean`
#function.
cacheSolve <- function(x, ...) {
inv <- x$getInverse()
if(!is.null(inv)) {
message("Grabbing your stored/cached data for you!")
return(inv)
}
data <- x$get()
inv <- solve(data, ...)
x$setmean(inv)
inv
}
x<- makeCacheMatrix(maxtrix(1:8,2,4))
x$getX()
x<- makeCacheMatrix(matrix(1:8,2,4))
x$getX()
cacheSolve(x)
## The following code can be used to:
## A) Create and store the inverse of a matrix
## B) Call a matrix, determine if its inverse has been computed and/or stored, then either compute the inverse or call the stored one
## The following fuction helps to create the matrix and can be used to store its inverse
makeCacheMatrix <- function(x = matrix()) {
inv <- NULL #Initializing where the inverse will be stored
setX<- function(y) { #Sets the matrix that will be worked with
x <<- y
inv <<- NULL
}
getX <- function() x #Simply grabbing the matrix
setInverse <- function(inverse) inv <<- inverse #Fuction to inverse the matrix
getInverse <- function() inv #Getting in the inverse
#Listing the functions so that they can used after makeCacheMatrix initializes X
list(setX = setX, getX = getX,
setInverse = setInverse,
getInverse = getInverse)
}
#The following function calculates the inverse of the matrix that
# was created with the above function. However, it first checks to see if the
#inverse has already been calculated. If so, it `get`s the inverse from the
#cache and skips the computation. Otherwise, it calculates the mean of
#the data and sets the value of the mean in the cache via the `setmean`
#function.
cacheSolve <- function(x, ...) {
inv <- x$getInverse()
if(!is.null(inv)) {
message("Grabbing your stored/cached data for you!")
return(inv)
}
data <- x$getX()
inv <- solve(data, ...)
x$setInverse(inv)
inv
}
x<- makeCacheMatrix(matrix(1:8,2,4))
x$getX()
solveCache(x)
cacheSolve(x)
x<- makeCacheMatrix(matrix(1:4,2,2))
solveCache(X)
cacheSolve(x)
cacheSolve(x)
library(datasets)
data("iris")
?iris
head(iris)
lapply(Sepal.Length, mean)
attach(iris)
lapply(Sepal.Length, mean)
sapply(Sepal.Length, mean)
head(iris)
mean(Sepal.Length[Species=='virginica'])
rowMeans(iris[,1:4])
rowMeans(iris[1:4,])
rowMeans(iris[1:4])
colMeans(iris[,1:4])
colMeans(iris)
colMeans(iris)
apply(iris,2,mean)
apply(iris[,1:4],2,mean)
attach(cars)
?cars
head(cars)
attach(mtcars)
?mtcars
head(mtcars)
tapply(mtcars$mpg, mtcars$cyl, mean)
abs(mean(mtcars[cyl=4]hp))
abs(mean(mtcars[cyl=4]$hp))
abs(mean(mtcars[cyl-=4]$hp))
abs(mean(mtcars[cyl==4]$hp))
abs(mean(mtcars[,cyl==4]$hp))
abs(mean(mtcars[,cyl==4]hp))
abs(mean(mtcars[cyl==4]hp))
debug
mean(hp[cyl==4]
)
mean(hp[cyl==4])-mean(hp[cyl==8])
mean(hp[cyl==4])-mean(hp[cyl==8])<-x
abs(mean(hp[cyl==4])-mean(hp[cyl==8]))
bebug(ls)
debug(ls)
ls
R.version.string
install.packages("swirl")
library(swirl)
swirl()
library(swirl)
install_from_swirl("Getting and Cleaning Data")
swirl()
read.csv(path2csv,stringsAsFactors = FALSE)
mydf<-read.csv(path2csv,stringsAsFactors = FALSE)
dim(mydf)
head()
head(mydf)
library(dplyr)
packageVersion(dplyr)
library(dplyr)
library("dplyr")
packageVersion("dplyr")
cran<-tbl_df(mydf)
rm("mydf")
?tbl_df
cran
?select
select(cran,ip_id,package,country)
5:20
select(cran,r_arch:country)
select(cran,country:r_arch)
cran
select(cran,-time)
select(cran,-X:Size)
select(cran,-X:size)
select(cran,-X:-size)
-5:20
-(5:20)
select(cran,-(X:-size))
select(cran,-(X:-ize))
select(cran,-(X:size))
filter(cran,package=="swirl")
filter(cran,r_version=="3.1.1",country=="US")
?Comparision
>Comparison
Comparison
?Comparison
filter(cran,r_version<="3.1.1",country=="India")
filter(cran,r_version<="3.1.1",country=="IN")
filter(cran,r_version<="3.0.2",country=="IN")
filter(cran,country=="US" | country=="IN")
filter(cran,size>100500, r_os=="linux-gnu")
is.na(c(3,5,NA,10))
!is.na(c(3,5,NA,10))
filter(cran,is.na(r_version)=TRUE)
filter(cran,is.na(r_version)==TRUE)
filter(cran,!is.na(r_version))
cran2<-select(cran,size:ip_id)
arrange(cran2,ip_id)
arrange(cran,desc(ip_id))
arrange(cran, desc(ip_id))
arrange(cran2, desc(ip_id))
arrange(cran2,package,ip_id)
arrange(cran2,country,desc(r_version), ip_id)
select(cran,ip_id,package,size)
select(cran, ip_id, package, size)
cran3<- select(cran,ip_id,package,size)
cran3
mutate(cran3, size_mb =size/2^20)
mutate(cran3, size_mb =size/2^20, size_gb=size_mb/2^10)
mutate(cran3,correct_size=size-1000)
mutate(cran3,correct_size=size+1000)
summarize(cran,avg_bytes=(mean(size)))
summarize(cran,avg_bytes=mean(size))
pnrom(93,mean=100,sd=10,upper.tail=FALSE)
pnorm(93,mean=100,sd=10,upper.tail=FALSE)
pnorm(93,mean=100,sd=10,lower.tail = TRUE)
pnorm(93,mean=100,sd=10)
pnorm(70,ean=80,sd=10)
pnorm(70,mean=80,sd=10)
pnorm(70,mean=80,sd=10, lower.tail = FALSE)
qnorm(95,mean=1100,sd=75, lower.tail = FALSE)
qnorm(95,mean=1100,sd=75)
qnorm(95)
pnorm(95)
qnorm(95)
answ3<-qnorm(95,mean=1100,sd=75)
round(answ3,0)
qnorm(0.95,mean=1100,sd=75)
qnorm(0.95,mean=1100,sd=75/10)
pnorm(4,0.5,lower.tail = FALSE)
pnorm(4,5,lower.tail = FALSE)
pnorm(4,size=5,prob=.5,lower.tail = FALSE)
pbinom(4,size=5,prob=.5,lower.tail = FALSE)
pbinom(3,size=5,prob=.5,lower.tail = FALSE)
ppois(10,14)
ppois(10,14,lower.tail = TRUE)
ppois(10,15,lower.tail = TRUE)
pnorm(70,mean=80,sd=10)
activity<-read.csv("activity.csv")
getwd()
setwd("..")
getwd()
setwd("./desktop/dstb/repo")
getwd
getwd()
activity<-read.csv("activity.csv")
setwd("./RepData_PeerAssessment1")
getwd()
activity<-read.csv("activity.csv")
activity$date<-as.Date(activity$date)
activity<-na.omit(activity)
library(dplyr)
activity<-tbl_df(activity)
daily_steps <- activity %>%
group_by(date) %>%
summarize(total_steps=sum(steps))
hist(daily_steps$total_steps, main="Total Steps per Day", xlab="Steps",col="purple")
step_stats <- daily_steps %>%
summarize(mean_steps=mean(total_steps),median_steps=median(total_steps))
```
interval<- activity %>%
group_by(interval) %>%
summarize(mean_steps=mean(steps))
plot(interval$interval,interval$mean_steps,type="l",xlab="Interval",ylab = "Average Steps Taken",
main="Average Steps taken during a 5 minute interval")
max_int<-interval$interval[which.max(interval$mean_steps)]
1.Calculate and report the total number of missing values in the dataset (i.e. the total number of rows with NAs)
- Since I originally removed the missings, I am reading back in the data
- Then using summary to see which variables have missing values
```{r echo=TRUE}
activity2<-read.csv("activity.csv")
activity2$date<-as.Date(activity2$date)
summary(activity2)
ggplot(activity3, aes(interval,steps)) +
ggtitle("Time Series Plot of Average Steps by Interval after Imputation") +
facet_grid(. ~ weekday) +
geom_line(size = 1)
library(ggplot2)
ggplot(activity3, aes(interval,steps)) +
ggtitle("Time Series Plot of Average Steps by Interval after Imputation") +
facet_grid(. ~ weekday) +
geom_line(size = 1)
activity3 <- activity2 %>%
group_by(daytype,interval) %>%
summarize(mean_int=mean(steps))
activity2$day<-as.factor(weekdays(activity2$date))
activity2$daytype<-"weekday"
---
title: "Peer Assessment 1"
---
**Loading and Processing the Data**
1. Load the Data
```{r echo=TRUE}
activity<-read.csv("activity.csv")
```
2. Transform the data as needed
- Updating Date to Date format
- Removing NAs
- Placing in tbl format to use dpylr
```{r echo=TRUE}
activity$date<-as.Date(activity$date)
activity<-na.omit(activity)
library(dplyr)
activity<-tbl_df(activity)
```
**What is mean total number of steps taken per day?**
1. Calculate the total number of steps taken per day
```{r echo=TRUE}
daily_steps <- activity %>%
group_by(date) %>%
summarize(total_steps=sum(steps))
```
2. Make a histogram of Steps per Day
```{r echo=TRUE}
hist(daily_steps$total_steps, main="Total Steps per Day", xlab="Steps",col="purple")
```
3. Calculate and report the mean and median of the total number of steps taken per day
```{r}
step_stats <- daily_steps %>%
summarize(mean_steps=mean(total_steps),median_steps=median(total_steps))
```
-The Mean number of steps taken per day is equal to `r step_stats$mean_steps`
-The Median number of steps taken per day is equal to `r step_stats$median_steps`
**What is the average daily activity pattern?**
1.Make a time series plot (i.e. type = "l") of the 5-minute interval (x-axis) and the average number of steps taken, averaged across all days (y-axis)
- First Summarize
- Then Plot
```{r}
interval<- activity %>%
group_by(interval) %>%
summarize(mean_steps=mean(steps))
plot(interval$interval,interval$mean_steps,type="l",xlab="Interval",ylab = "Average Steps Taken",
main="Average Steps taken during a 5 minute interval")
```
2.Which 5-minute interval, on average across all the days in the dataset, contains the maximum number of steps?
```{r}
max_int<-interval$interval[which.max(interval$mean_steps)]
```
-The Maximum average steps took place during interval `r max_int`
**Imputing missing values**
1.Calculate and report the total number of missing values in the dataset (i.e. the total number of rows with NAs)
- Since I originally removed the missings, I am reading back in the data
- Then using summary to see which variables have missing values
```{r echo=TRUE}
activity2<-read.csv("activity.csv")
activity2$date<-as.Date(activity2$date)
summary(activity2)
```
- Since Steps is the only variable with missing values, that is the only variable I need to count for missings
```{r echo=TRUE}
missings<-sum(is.na(activity2$steps))
```
- The total number of missing values is `r missings`
2.Devise a strategy for filling in all of the missing values in the dataset. The strategy does not need to be sophisticated. For example, you could use the mean/median for that day, or the mean for that 5-minute interval, etc.
- I am going to fill in the median number of average steps per interval step
- Average number of steps per interval is saved in interval already, just need to find median
3.Create a new dataset that is equal to the original dataset but with the missing data filled in.
```{r echo=TRUE}
int_med<- interval %>%
summarize(med=median(mean_steps))
for (i in 1:nrow(activity2)) {
if (is.na(activity2$steps[i])) {
activity2$steps[i] <- int_med$med
}
}
summary(activity2)
```
- There are no longer any missings
4.Make a histogram of the total number of steps taken each day and Calculate and report the mean and median total number of steps taken per day.
- First I will need to get total steps per day, then I can plot the histogram
```{r echo=TRUE}
new_sum<- activity2 %>%
group_by(date)%>%
summarize(total_steps=sum(steps))
hist(new_sum$total_steps, main="Total Steps per Day", xlab="Steps",col="purple")
```
- Mean and Median Steps
```{r echo=TRUE}
new_stats<- new_sum %>%
summarize(mean_steps=mean(total_steps),med_steps=mean(total_steps))
```
- These values are different:
- Mean
- Old `r step_stats$mean_steps`
- New `r new_stats$mean_steps`
- Median
- Old `r step_stats$median_steps`
- New `r new_stats$med_steps`
- The impact is mean average and median steps
**Are there differences in activity patterns between weekdays and weekends?**
1.Create a new factor variable in the dataset with two levels - "weekday" and "weekend" indicating whether a given date is a weekday or weekend day.
- Figure out Day of week with weekdays()
- Assign daytype orginally to weekday
- change Day Type on Sat/Sun
```{r echo=TRUE}
activity2$day<-as.factor(weekdays(activity2$date))
activity2$daytype<-"weekday"
activity2$daytype[activity2$day %in% c("Saturday", "Sunday")] <- "weekend"
activity2$daytype<-as.factor(activity2$daytype)
```
2.Make a panel plot containing a time series plot (i.e. type = "l") of the 5-minute interval (x-axis) and the average number of steps taken, averaged across all weekday days or weekend days (y-axis).
```{r echo=TRUE}
activity3 <- activity2 %>%
group_by(daytype,interval) %>%
summarize(mean_int=mean(steps))
library(ggplot2)
ggplot(activity3, aes(x=interval, y=mean_int, group=daytype, color=daytype))+
geom_line()+
xlab("Interval")+
ylab("Average Steps")+
ggtitle("Average Steps per Interval Steps Weekday vs Weekend")
ggplot(activity3, aes(interval,steps)) +
ggtitle("Time Series Plot of Average Steps by Interval after Imputation") +
facet_grid(. ~ weekday) +
geom_line(size = 1)
```
ggplot(activity3, aes(x=interval, y=mean_int, group=daytype, color=daytype))+
geom_line()+
xlab("Interval")+
ylab("Average Steps")+
ggtitle("Average Steps per Interval Steps Weekday vs Weekend")
ggplot(activity3, aes(interval,steps)) +
ggtitle("Time Series Plot of Average Steps by Interval after Imputation") +
facet_grid(. ~ weekday) +
geom_line(size = 1)
activity3 <- activity2 %>%
group_by(daytype,interval) %>%
summarize(mean_int=mean(steps))
ggplot(activity3, aes(interval,steps)) +
ggtitle("Time Series Plot of Average Steps by Interval after Imputation") +
facet_grid(. ~ daytype) +
geom_line(size = 1)
ggplot(activity3, aes(interval,mean_int)) +
ggtitle("Time Series Plot of Average Steps by Interval after Imputation") +
facet_grid(. ~ daytype) +
geom_line(size = 1)
ggplot(activity3, aes(interval,mean_int)) +
ggtitle("Time Series Plot of Average Steps by Interval after Imputation") +
facet_grid(. ~ daytype) +
geom_line(size = 1, color="purple") +
```
ggplot(activity3, aes(interval,mean_int)) +
ggtitle("Time Series Plot of Average Steps by Interval after Imputation") +
facet_grid(. ~ daytype) +
geom_line(size = 1, color="purple")
knit2html("PA1_template.Rmd")
library("knitr", lib.loc="~/R/R-3.2.1/library")
knit2html("PA1_template.Rmd")
